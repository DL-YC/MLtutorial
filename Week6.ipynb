{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "\n",
    "## Debugging a learning algorithm\n",
    "\n",
    "Which of these should I choose to do better?\n",
    "\n",
    "- Get more training examples\n",
    "- Try smaller sets of features\n",
    "- Try getting additional features\n",
    "- Try adding polynomial features\n",
    "- Try decreasing $\\lambda$\n",
    "- Try increasing $\\lambda$\n",
    "\n",
    "\n",
    "1. How to evaluate algorihtms\n",
    "2. How to run machine learning diagnostics\n",
    "\n",
    "Diagnostics can take a lot of time to implement, but can end up saving you even more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a hypothesis\n",
    "\n",
    "When we try to fit our parameters, we try to make it so our parameters fit our training data.  But do not want to overfit.\n",
    "\n",
    "Standard way to evaluate the hypothesis:\n",
    "\n",
    "- Split 70% of sample data into the \"training set\"\n",
    "- Split other 30% of sample data into the \"test set\"\n",
    "\n",
    "#### Training/testing procedure for linear regression\n",
    "\n",
    "- Learn parameter $\\theta$ from training data (minimizing training error $J(\\Theta)$)\n",
    "- Compute test set error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and train/validation/test sets\n",
    "\n",
    "Split 60 / 20 / 20\n",
    "\n",
    "### Diagnosing bias vs. variance\n",
    "\n",
    "- Plot degree of polynomial d on x axis and error on y axis\n",
    "\n",
    "- As we increase degree of polynomial, will be able to fit our set better\n",
    "\n",
    "- Or if we look at test set error\n",
    "\n",
    "- Bias = underfit\n",
    "\n",
    "$J_{train}$ will be high\n",
    "$J_{CV} approx J_{train}$\n",
    "\n",
    "- Variance = overfit\n",
    "\n",
    "$J_{train} will be low$\n",
    "$J_{CV} will be high$\n",
    "\n",
    "### Regularization and Bias/Variance\n",
    "\n",
    "- Let's go deeper into bias and variance\n",
    "\n",
    "Suppose fitting high order polynomial\n",
    "\n",
    "- Large $\\lambda$ (underfit)\n",
    "- Intermediate $\\lambda$ (just right)\n",
    "- Small $\\lambda$ (overfit)\n",
    "\n",
    "Choosing the regularization parameter $\\lambda$\n",
    "\n",
    "1. Try $\\lambda = 0$\n",
    "2. Try $\\lambda = 0.01$\n",
    "3. Try $\\lambda = 0.02$\n",
    "4. Try $\\lambda = 0.04$\n",
    "5. Try $\\lambda = 0.08$\n",
    "\n",
    "...\n",
    "\n",
    "\\12. Try $\\lambda = 10$\n",
    "\n",
    "### Learning curves\n",
    "\n",
    "Plot\n",
    "\n",
    "$J_{train} = \\frac{1}{2m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 $\n",
    "\n",
    "$J_{CV} = \\frac{1}{2m_{cv}} \\sum_{i=1}^{m_{CV}}(h_{\\theta}(x^{(i)}_{CV}) - y^{(i)}_{CV})^2 $\n",
    "\n",
    "### Deciding what to do next\n",
    "\n",
    "Suppose you have implemented regularized linear regression to predict housing prices.  However, when you test your hypothesis in a new set of houses, you find that it makes unacceptably larger errors in its prediction\n",
    "\n",
    "- Get more training examples --> fixes high variance\n",
    "- Try smaller sets of features --> fixes high variance\n",
    "- Try getting additional features --> fixes high bias\n",
    "- Try adding polynomial features --> fixes high bias\n",
    "- Try decreasing $\\lambda$ --> fixes high bias\n",
    "- Try increasing $\\lambda$ --> fixes high variance\n",
    "\n",
    "####\"Small\" neural network\n",
    "- fewer parameters, more prone to underfitting\n",
    "\n",
    "####\"Large\" neural network\n",
    "- more parameters, more prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning system design\n",
    "\n",
    "Would like to begin with the issue of how to spend your time.\n",
    "\n",
    "Building a spam classifier\n",
    "\n",
    "Supervised learning.\n",
    "\n",
    "$x=$ features of email\n",
    "$y=$ spam(1) or not spam(0)\n",
    "\n",
    "e.g. deal, buy, discount, andrew, now...\n",
    "\n",
    "### Error Analysis\n",
    "\n",
    "Recommended approach\n",
    "\n",
    "- Start with a simple algorithm that you can implement quickly.\n",
    "- At most 24 hours to get something quick and dirty running.\n",
    "- Then plot learning curves to decide if more data, more deatures, etc. are likely to help\n",
    "- Error analysis: manually examine the examples (in cross validation set) that your algorithm made errors on.  See if you spot any systematic trend in what type of examples it is making errors on.\n",
    "\n",
    "$m_{cv} = 500$ examples in cross validation set\n",
    "Algorithm misclassifies 100 emails\n",
    "Manually examine the 100 errors, and categorize them based on:\n",
    "\n",
    "(i) what type of email it is\n",
    "(ii) what cues (features) you think wouild have helped the algorithm classify them correctly\n",
    "\n",
    "### Error metrics for skewed classes\n",
    "\n",
    "Cancer classification example\n",
    "\n",
    "- Train logistic regression model $h_{\\theta}(x)$. ($y=1$ if cancer, $y=0$ otherwise)\n",
    "\n",
    "Find that you got 1% error on test set. (99% correct diagnoses)\n",
    "\n",
    "Only 0.50% of patients have cancer\n",
    "\n",
    "If your function is just y=0, ignore x, than you only have 0.5% error.\n",
    "\n",
    "This is called skewed classes\n",
    "\n",
    "99.2% accuracy to 99.5% accuracy sounds good, but it's not clear if it's improving the value of your classifier.\n",
    "\n",
    "When faced with skewed classes, want to have a different metric.\n",
    "\n",
    "#### Precision / recall\n",
    "\n",
    "Predict $y=1$ in presence of rare class that we want to detect\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{True positives}}{\\text{# predicted positive}} $$\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{True positives}}{\\text{# actual positive}} $$\n",
    "\n",
    "Want both high precision and recall.\n",
    "\n",
    "Define such taht $y=1$ in presence of the rare class.\n",
    "\n",
    "### Trading off precision and recall\n",
    "\n",
    "$F_1 Score: 2\\frac{PR}{P + R}$\n",
    "\n",
    "## Data for machine learning\n",
    "\n",
    "How much data should I train on?\n",
    "\n",
    "Under certain conditions, getting a lot of data, can be very effective.\n",
    "\n",
    "#### Designing a high accuracy learning system\n",
    "\n",
    "E.g. Classify between confusable words.\n",
    "\n",
    "{to, two,. too} {then, than}\n",
    "\n",
    "For breakfast I ate _two_ eggs.\n",
    "\n",
    "Algorithms\n",
    "\n",
    "- Perceptron (logistic regression)\n",
    "- Winnow\n",
    "- Memory-based\n",
    "- Naive bayes\n",
    "\n",
    "All algorithms get better with more data.\n",
    "\n",
    "[Banko and Brill, 2001]\n",
    "\n",
    "\"It's not who has the best algorithm that wins.  It's who has the most data\"\n",
    "\n",
    "#### Large data rationale\n",
    "\n",
    "Assume feature $x \\in \\mathbb{R}^{n+1}$ has sufficient information to predict $y$ accurately.\n",
    "\n",
    "Example: for breakfast I ate _two_ eggs.\n",
    "\n",
    "Counterexample: predict housing price from only size (feet^2) and no other features.\n",
    "\n",
    "Useful test: given the input $x$, can a human expert confidently predict $y$?\n",
    "\n",
    "Use a learning algorithm with many parameters (e.g. logistic regression / linear regression with many features; neural network with many hidden unites)\n",
    "\n",
    "Use a very large training set (unlikely to overfit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
